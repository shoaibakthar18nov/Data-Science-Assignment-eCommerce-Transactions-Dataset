{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1: Import Required Libraries\n",
    "\n",
    "Start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load Data\n",
    "\n",
    "Load the three datasets into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Check the first few rows of each dataset to understand their structure\n",
    "print(customers.head())\n",
    "print(products.head())\n",
    "print(transactions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Data Preprocessing\n",
    "\n",
    "Before building the model, clean and merge the datasets.\n",
    "\n",
    "    Merge Customers.csv and Transactions.csv on CustomerID.\n",
    "    Merge the resulting DataFrame with Products.csv on ProductID.\n",
    "    Aggregate transaction data for each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge customers with their transactions\n",
    "merged_data = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
    "\n",
    "# Merge with products to get product information\n",
    "merged_data = pd.merge(merged_data, products[['ProductID', 'Category', 'Price']], on='ProductID', how='left')\n",
    "\n",
    "# Aggregate data for each customer (total spent, number of transactions, etc.)\n",
    "customer_data = merged_data.groupby('CustomerID').agg(\n",
    "    total_spent=('TotalValue', 'sum'),\n",
    "    num_transactions=('TransactionID', 'nunique'),\n",
    "    avg_spent_per_transaction=('TotalValue', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Include customer demographic data (like region)\n",
    "customer_data = pd.merge(customer_data, customers[['CustomerID', 'Region']], on='CustomerID', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Feature Engineering\n",
    "\n",
    "Now, create features based on transaction history and customer demographics.\n",
    "\n",
    "    Normalize the numerical features (total spent, number of transactions, etc.).\n",
    "    One-hot encode categorical features like region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  total_spent  num_transactions  avg_spent_per_transaction  \\\n",
      "0      C0001    -0.061701         -0.011458                  -0.070263   \n",
      "1      C0002    -0.877744         -0.467494                  -0.934933   \n",
      "2      C0003    -0.405857         -0.467494                  -0.026271   \n",
      "3      C0004     1.032547          1.356650                  -0.076769   \n",
      "4      C0005    -0.783929         -0.923530                  -0.040028   \n",
      "\n",
      "   Region_Europe  Region_North America  Region_South America  \n",
      "0              0                     0                     1  \n",
      "1              0                     0                     0  \n",
      "2              0                     0                     1  \n",
      "3              0                     0                     1  \n",
      "4              0                     0                     0  \n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "customer_data[['total_spent', 'num_transactions', 'avg_spent_per_transaction']] = scaler.fit_transform(\n",
    "    customer_data[['total_spent', 'num_transactions', 'avg_spent_per_transaction']]\n",
    ")\n",
    "\n",
    "# One-hot encode the 'Region' feature\n",
    "customer_data = pd.get_dummies(customer_data, columns=['Region'], drop_first=True)\n",
    "\n",
    "# Check the final processed data\n",
    "print(customer_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Build the Lookalike Model\n",
    "\n",
    "Now, we'll compute the similarity between customers using Cosine Similarity.\n",
    "\n",
    "    Cosine similarity measures the angle between two vectors. The closer the angle is to 0, the more similar the customers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID\n",
      "C0001    1.000000\n",
      "C0137    0.999762\n",
      "C0152    0.999510\n",
      "C0107    0.964169\n",
      "C0191    0.945666\n",
      "Name: C0001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "customer_features = customer_data.drop('CustomerID', axis=1)  # Drop CustomerID for similarity calculation\n",
    "similarity_matrix = cosine_similarity(customer_features)\n",
    "\n",
    "# Convert the similarity matrix to a DataFrame\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_data['CustomerID'], columns=customer_data['CustomerID'])\n",
    "\n",
    "# Check the similarity matrix for customer C0001\n",
    "print(similarity_df['C0001'].sort_values(ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Generate Top 3 Lookalikes for Each Customer\n",
    "\n",
    "Now, for each customer, we'll find their top 3 most similar customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the top 3 most similar customers\n",
    "def get_top_3_lookalikes(customer_id, similarity_df):\n",
    "    similar_customers = similarity_df[customer_id].sort_values(ascending=False)[1:4]  # Exclude the customer itself\n",
    "    return similar_customers.index.tolist(), similar_customers.values.tolist()\n",
    "\n",
    "# Prepare the Lookalike.csv data\n",
    "lookalike_data = []\n",
    "for customer_id in customer_data['CustomerID'].head(20):  # For C0001 to C0020\n",
    "    lookalike_ids, scores = get_top_3_lookalikes(customer_id, similarity_df)\n",
    "    for i, lookalike_id in enumerate(lookalike_ids):\n",
    "        lookalike_data.append([customer_id, lookalike_id, scores[i]])\n",
    "\n",
    "# Create a DataFrame for the lookalikes\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'LookalikeID', 'SimilarityScore'])\n",
    "\n",
    "# Save the results to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Output the Results\n",
    "\n",
    "The Lookalike.csv file will contain the top 3 lookalikes for each of the first 20 customers (CustomerID: C0001 - C0020) along with their similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CustomerID,LookalikeID,SimilarityScore\n",
    "C0001,C0137,0.9997616475513844\n",
    "C0001,C0152,0.9995103764905026\n",
    "C0001,C0107,0.9641690971679807\n",
    "C0002,C0043,0.9928719995078378\n",
    "C0002,C0142,0.9808733720413273\n",
    "C0002,C0097,0.9755037432206866\n",
    "C0003,C0133,0.98706169870118\n",
    "C0003,C0052,0.9754103448062152\n",
    "C0003,C0112,0.9415781873172182\n",
    "C0004,C0108,0.9827182639674003\n",
    "C0004,C0113,0.9785391786723804\n",
    "C0004,C0165,0.9738306048704476\n",
    "C0005,C0178,0.9990813407657672\n",
    "C0005,C0159,0.9989277207729346\n",
    "C0005,C0123,0.997904546931205\n",
    "C0006,C0168,0.978264001321209\n",
    "C0006,C0158,0.9711446209691191\n",
    "C0006,C0171,0.9387564178572096\n",
    "C0007,C0140,0.9978130376911358\n",
    "C0007,C0092,0.9926503090011995\n",
    "C0007,C0193,0.9911395081011377\n",
    "C0008,C0139,0.9721988310054218\n",
    "C0008,C0109,0.9698722815670315\n",
    "C0008,C0098,0.9307192939474349\n",
    "C0009,C0060,0.9818423255580481\n",
    "C0009,C0010,0.9807961382416003\n",
    "C0009,C0121,0.9798524547998502\n",
    "C0010,C0199,0.9923026397421746\n",
    "C0010,C0009,0.9807961382416003\n",
    "C0010,C0121,0.9758346484079298\n",
    "C0011,C0107,0.9948966873068459\n",
    "C0011,C0048,0.9941231099438982\n",
    "C0011,C0152,0.9433269615596138\n",
    "C0012,C0155,0.9982299602323986\n",
    "C0012,C0108,0.9846023642070699\n",
    "C0012,C0102,0.9836692611849275\n",
    "C0013,C0087,0.9898279481555508\n",
    "C0013,C0188,0.9888834548638371\n",
    "C0013,C0099,0.9861744175216884\n",
    "C0014,C0198,0.9889759898914686\n",
    "C0014,C0060,0.9756975141606177\n",
    "C0014,C0009,0.9615398807230745\n",
    "C0015,C0144,0.9895384745128599\n",
    "C0015,C0036,0.9834692674657693\n",
    "C0015,C0131,0.9772816942628351\n",
    "C0016,C0183,0.9997857762658623\n",
    "C0016,C0026,0.8763642657316434\n",
    "C0016,C0018,0.8656919178748971\n",
    "C0017,C0124,0.9795659241713703\n",
    "C0017,C0075,0.9692050858710901\n",
    "C0017,C0162,0.8444702818939048\n",
    "C0018,C0079,0.9391808907106641\n",
    "C0018,C0117,0.9299131166822665\n",
    "C0018,C0016,0.8656919178748971\n",
    "C0019,C0172,0.9999897107239059\n",
    "C0019,C0111,0.9660184815998832\n",
    "C0019,C0119,0.9535765014314451\n",
    "C0020,C0042,0.9474090450742292\n",
    "C0020,C0176,0.9443114466284428\n",
    "C0020,C0110,0.9283838464103554\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
